{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKIN DISEASE IDENTIFICATION USING IMAGE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape = (64,64,3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape = (64,64,3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Maxpooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add flattening layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 28800)             0         \n",
      "=================================================================\n",
      "Total params: 10,144\n",
      "Trainable params: 10,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim = 128, init = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim = 128, init = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim = 64, init = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim = 64, init = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=5, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim = 5, init = 'uniform', activation = 'softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, height_shift_range = 0.2, width_shift_range = 0.2, horizontal_flip = True, vertical_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2205 images belonging to 5 classes.\n",
      "Found 550 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'C:\\Users\\Disha chugh\\Desktop\\major project\\Skin Diseases\\Skin Diseases\\train', target_size = (64, 64), batch_size = 32, class_mode = 'categorical')\n",
    "x_test = test_datagen.flow_from_directory(r'C:\\Users\\Disha chugh\\Desktop\\major project\\Skin Diseases\\Skin Diseases\\test', target_size = (64, 64), batch_size = 32, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acne': 0, 'Melanoma': 1, 'Psoriasis': 2, 'Rosacea': 3, 'Vitiligo': 4}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Disha chugh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/200\n",
      "100/100 [==============================] - 85s 853ms/step - loss: 1.6063 - accuracy: 0.2354 - val_loss: 6.8287 - val_accuracy: 0.3566\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - 38s 383ms/step - loss: 1.5401 - accuracy: 0.2990 - val_loss: 97.9538 - val_accuracy: 0.3039\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - 39s 387ms/step - loss: 1.5090 - accuracy: 0.3125 - val_loss: 161.2406 - val_accuracy: 0.3029\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 36s 361ms/step - loss: 1.4790 - accuracy: 0.3237 - val_loss: 56.4342 - val_accuracy: 0.3379\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 1.4379 - accuracy: 0.3723 - val_loss: 102.7375 - val_accuracy: 0.3808\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - 38s 383ms/step - loss: 1.4317 - accuracy: 0.3848 - val_loss: 172.3705 - val_accuracy: 0.3755\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - 40s 403ms/step - loss: 1.4078 - accuracy: 0.3941 - val_loss: 56.1999 - val_accuracy: 0.3375\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 43s 425ms/step - loss: 1.3998 - accuracy: 0.3885 - val_loss: 215.6457 - val_accuracy: 0.3243\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - 48s 476ms/step - loss: 1.3864 - accuracy: 0.3992 - val_loss: 160.7438 - val_accuracy: 0.3080\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - 45s 449ms/step - loss: 1.3770 - accuracy: 0.4060 - val_loss: 222.7352 - val_accuracy: 0.3060\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - 40s 397ms/step - loss: 1.3646 - accuracy: 0.3976 - val_loss: 129.7258 - val_accuracy: 0.3545\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 42s 422ms/step - loss: 1.3569 - accuracy: 0.4086 - val_loss: 288.6884 - val_accuracy: 0.3018\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - 41s 409ms/step - loss: 1.3251 - accuracy: 0.4273 - val_loss: 235.0008 - val_accuracy: 0.2884\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - 41s 407ms/step - loss: 1.3060 - accuracy: 0.4404 - val_loss: 136.2083 - val_accuracy: 0.4116\n",
      "Epoch 15/200\n",
      "100/100 [==============================] - 36s 364ms/step - loss: 1.2821 - accuracy: 0.4640 - val_loss: 156.7333 - val_accuracy: 0.3860\n",
      "Epoch 16/200\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 1.2687 - accuracy: 0.4733 - val_loss: 219.2471 - val_accuracy: 0.3342\n",
      "Epoch 17/200\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.2468 - accuracy: 0.4796 - val_loss: 423.9897 - val_accuracy: 0.2766\n",
      "Epoch 18/200\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 1.2550 - accuracy: 0.4845 - val_loss: 148.0819 - val_accuracy: 0.4236\n",
      "Epoch 19/200\n",
      "100/100 [==============================] - 35s 352ms/step - loss: 1.2486 - accuracy: 0.4796 - val_loss: 107.8315 - val_accuracy: 0.3829\n",
      "Epoch 20/200\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.2313 - accuracy: 0.4861 - val_loss: 290.2600 - val_accuracy: 0.3923\n",
      "Epoch 21/200\n",
      "100/100 [==============================] - 39s 395ms/step - loss: 1.2211 - accuracy: 0.4948 - val_loss: 292.4077 - val_accuracy: 0.3039\n",
      "Epoch 22/200\n",
      "100/100 [==============================] - 44s 443ms/step - loss: 1.2311 - accuracy: 0.4925 - val_loss: 306.0386 - val_accuracy: 0.2694\n",
      "Epoch 23/200\n",
      "100/100 [==============================] - 39s 386ms/step - loss: 1.2215 - accuracy: 0.4961 - val_loss: 222.1802 - val_accuracy: 0.3854\n",
      "Epoch 24/200\n",
      "100/100 [==============================] - 37s 370ms/step - loss: 1.2181 - accuracy: 0.5019 - val_loss: 232.2521 - val_accuracy: 0.2301\n",
      "Epoch 25/200\n",
      "100/100 [==============================] - 38s 381ms/step - loss: 1.2311 - accuracy: 0.4920 - val_loss: 210.5633 - val_accuracy: 0.2926\n",
      "Epoch 26/200\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.1752 - accuracy: 0.5157 - val_loss: 211.3340 - val_accuracy: 0.3211\n",
      "Epoch 27/200\n",
      "100/100 [==============================] - 36s 361ms/step - loss: 1.1972 - accuracy: 0.5102 - val_loss: 163.7159 - val_accuracy: 0.3055\n",
      "Epoch 28/200\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.1795 - accuracy: 0.5170 - val_loss: 323.6800 - val_accuracy: 0.3813\n",
      "Epoch 29/200\n",
      "100/100 [==============================] - 35s 355ms/step - loss: 1.2000 - accuracy: 0.5094 - val_loss: 256.3488 - val_accuracy: 0.3024\n",
      "Epoch 30/200\n",
      "100/100 [==============================] - 36s 362ms/step - loss: 1.1580 - accuracy: 0.5286 - val_loss: 314.0817 - val_accuracy: 0.3556\n",
      "Epoch 31/200\n",
      "100/100 [==============================] - 35s 352ms/step - loss: 1.1666 - accuracy: 0.5285 - val_loss: 130.3195 - val_accuracy: 0.4051\n",
      "Epoch 32/200\n",
      "100/100 [==============================] - 37s 375ms/step - loss: 1.1545 - accuracy: 0.5211 - val_loss: 332.8925 - val_accuracy: 0.3520\n",
      "Epoch 33/200\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 1.1470 - accuracy: 0.5294 - val_loss: 430.0780 - val_accuracy: 0.3075\n",
      "Epoch 34/200\n",
      "100/100 [==============================] - 44s 443ms/step - loss: 1.1300 - accuracy: 0.5416 - val_loss: 127.3818 - val_accuracy: 0.3091\n",
      "Epoch 35/200\n",
      "100/100 [==============================] - 35s 350ms/step - loss: 1.1471 - accuracy: 0.5355 - val_loss: 213.6814 - val_accuracy: 0.3488\n",
      "Epoch 36/200\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.1315 - accuracy: 0.5352 - val_loss: 294.7983 - val_accuracy: 0.3049\n",
      "Epoch 37/200\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 1.1339 - accuracy: 0.5463 - val_loss: 289.3566 - val_accuracy: 0.3359\n",
      "Epoch 38/200\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 1.1140 - accuracy: 0.5443 - val_loss: 220.3182 - val_accuracy: 0.4399\n",
      "Epoch 39/200\n",
      "100/100 [==============================] - 35s 353ms/step - loss: 1.1036 - accuracy: 0.5582 - val_loss: 415.1541 - val_accuracy: 0.2910\n",
      "Epoch 40/200\n",
      "100/100 [==============================] - 35s 352ms/step - loss: 1.1079 - accuracy: 0.5486 - val_loss: 36.8362 - val_accuracy: 0.3980\n",
      "Epoch 41/200\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 1.0908 - accuracy: 0.5599 - val_loss: 225.1517 - val_accuracy: 0.3973\n",
      "Epoch 42/200\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.0871 - accuracy: 0.5595 - val_loss: 262.2775 - val_accuracy: 0.2950\n",
      "Epoch 43/200\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 1.0913 - accuracy: 0.5513 - val_loss: 351.2697 - val_accuracy: 0.3369\n",
      "Epoch 44/200\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.0644 - accuracy: 0.5702 - val_loss: 420.6198 - val_accuracy: 0.3122\n",
      "Epoch 45/200\n",
      "100/100 [==============================] - 36s 365ms/step - loss: 1.0963 - accuracy: 0.5511 - val_loss: 408.8377 - val_accuracy: 0.3003\n",
      "Epoch 46/200\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 1.0546 - accuracy: 0.5840 - val_loss: 101.0421 - val_accuracy: 0.4095\n",
      "Epoch 47/200\n",
      "100/100 [==============================] - 36s 360ms/step - loss: 1.0712 - accuracy: 0.5689 - val_loss: 345.1913 - val_accuracy: 0.3003\n",
      "Epoch 48/200\n",
      "100/100 [==============================] - 36s 361ms/step - loss: 1.0449 - accuracy: 0.5740 - val_loss: 377.7037 - val_accuracy: 0.3023\n",
      "Epoch 49/200\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 1.0504 - accuracy: 0.5739 - val_loss: 450.3435 - val_accuracy: 0.3117\n",
      "Epoch 50/200\n",
      "100/100 [==============================] - 36s 364ms/step - loss: 1.0414 - accuracy: 0.5805 - val_loss: 248.0712 - val_accuracy: 0.3740\n",
      "Epoch 51/200\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.0462 - accuracy: 0.5793 - val_loss: 409.3690 - val_accuracy: 0.3050\n",
      "Epoch 52/200\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 1.0287 - accuracy: 0.5859 - val_loss: 548.6248 - val_accuracy: 0.3122\n",
      "Epoch 53/200\n",
      "100/100 [==============================] - 38s 381ms/step - loss: 1.0268 - accuracy: 0.5939 - val_loss: 531.4152 - val_accuracy: 0.2699\n",
      "Epoch 54/200\n",
      "100/100 [==============================] - 40s 395ms/step - loss: 1.0099 - accuracy: 0.5983 - val_loss: 540.8628 - val_accuracy: 0.3128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "100/100 [==============================] - 39s 390ms/step - loss: 1.0291 - accuracy: 0.5894 - val_loss: 434.8002 - val_accuracy: 0.3287\n",
      "Epoch 56/200\n",
      "100/100 [==============================] - 42s 421ms/step - loss: 1.0032 - accuracy: 0.6002 - val_loss: 228.5770 - val_accuracy: 0.3713\n",
      "Epoch 57/200\n",
      "100/100 [==============================] - 41s 406ms/step - loss: 1.0285 - accuracy: 0.5895 - val_loss: 396.4593 - val_accuracy: 0.3080\n",
      "Epoch 58/200\n",
      "100/100 [==============================] - 34s 336ms/step - loss: 1.0069 - accuracy: 0.5965 - val_loss: 274.0473 - val_accuracy: 0.3970\n",
      "Epoch 59/200\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.9828 - accuracy: 0.6096 - val_loss: 299.6619 - val_accuracy: 0.4706\n",
      "Epoch 60/200\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.9996 - accuracy: 0.6043 - val_loss: 524.5865 - val_accuracy: 0.3525\n",
      "Epoch 61/200\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.9632 - accuracy: 0.6124 - val_loss: 347.4411 - val_accuracy: 0.4231\n",
      "Epoch 62/200\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.9933 - accuracy: 0.5996 - val_loss: 457.6269 - val_accuracy: 0.4001\n",
      "Epoch 63/200\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.9843 - accuracy: 0.6037 - val_loss: 429.9595 - val_accuracy: 0.3493\n",
      "Epoch 64/200\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 0.9776 - accuracy: 0.6130 - val_loss: 277.9028 - val_accuracy: 0.4017\n",
      "Epoch 65/200\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.9591 - accuracy: 0.6183 - val_loss: 341.9756 - val_accuracy: 0.3586\n",
      "Epoch 66/200\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 0.9883 - accuracy: 0.6118 - val_loss: 100.1771 - val_accuracy: 0.3096\n",
      "Epoch 67/200\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 0.9846 - accuracy: 0.6112 - val_loss: 353.6540 - val_accuracy: 0.3519\n",
      "Epoch 68/200\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.9519 - accuracy: 0.6246 - val_loss: 276.2088 - val_accuracy: 0.3708\n",
      "Epoch 69/200\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 0.9546 - accuracy: 0.6237 - val_loss: 275.9620 - val_accuracy: 0.3849\n",
      "Epoch 70/200\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 0.9266 - accuracy: 0.6356 - val_loss: 280.0378 - val_accuracy: 0.3849\n",
      "Epoch 71/200\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.9434 - accuracy: 0.6162 - val_loss: 448.0281 - val_accuracy: 0.3818\n",
      "Epoch 72/200\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 0.9342 - accuracy: 0.6290 - val_loss: 434.3371 - val_accuracy: 0.3912\n",
      "Epoch 73/200\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 0.9237 - accuracy: 0.6365 - val_loss: 218.2468 - val_accuracy: 0.4216\n",
      "Epoch 74/200\n",
      "100/100 [==============================] - 32s 316ms/step - loss: 0.9568 - accuracy: 0.6178 - val_loss: 270.4908 - val_accuracy: 0.3609\n",
      "Epoch 75/200\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 0.8860 - accuracy: 0.6509 - val_loss: 502.4008 - val_accuracy: 0.3720\n",
      "Epoch 76/200\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 0.9346 - accuracy: 0.6303 - val_loss: 388.3941 - val_accuracy: 0.4482\n",
      "Epoch 77/200\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 0.9203 - accuracy: 0.6302 - val_loss: 449.6023 - val_accuracy: 0.3777\n",
      "Epoch 78/200\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 0.8937 - accuracy: 0.6515 - val_loss: 454.6464 - val_accuracy: 0.3933\n",
      "Epoch 79/200\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 0.9112 - accuracy: 0.6425 - val_loss: 336.1638 - val_accuracy: 0.4061\n",
      "Epoch 80/200\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 0.9161 - accuracy: 0.6340 - val_loss: 785.2195 - val_accuracy: 0.3604\n",
      "Epoch 81/200\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.8881 - accuracy: 0.6484 - val_loss: 394.0701 - val_accuracy: 0.4169\n",
      "Epoch 82/200\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 0.8768 - accuracy: 0.6509 - val_loss: 445.7123 - val_accuracy: 0.4163\n",
      "Epoch 83/200\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 0.8929 - accuracy: 0.6359 - val_loss: 249.8975 - val_accuracy: 0.4200\n",
      "Epoch 84/200\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 0.8647 - accuracy: 0.6572 - val_loss: 122.3316 - val_accuracy: 0.4393\n",
      "Epoch 85/200\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 0.8875 - accuracy: 0.6581 - val_loss: 409.8426 - val_accuracy: 0.3462\n",
      "Epoch 86/200\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 0.8539 - accuracy: 0.6515 - val_loss: 374.2052 - val_accuracy: 0.3337\n",
      "Epoch 87/200\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.8680 - accuracy: 0.6578 - val_loss: 292.5135 - val_accuracy: 0.4040\n",
      "Epoch 88/200\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 0.8542 - accuracy: 0.6569 - val_loss: 365.6681 - val_accuracy: 0.3389\n",
      "Epoch 89/200\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 0.8544 - accuracy: 0.6575 - val_loss: 637.7595 - val_accuracy: 0.3581\n",
      "Epoch 90/200\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 0.8654 - accuracy: 0.6597 - val_loss: 334.0017 - val_accuracy: 0.4231\n",
      "Epoch 91/200\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 0.8855 - accuracy: 0.6512 - val_loss: 270.9458 - val_accuracy: 0.4071\n",
      "Epoch 92/200\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 0.8528 - accuracy: 0.6600 - val_loss: 316.3217 - val_accuracy: 0.3478\n",
      "Epoch 93/200\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 0.8913 - accuracy: 0.6506 - val_loss: 187.8253 - val_accuracy: 0.4768\n",
      "Epoch 94/200\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.8181 - accuracy: 0.6709 - val_loss: 425.0467 - val_accuracy: 0.4059\n",
      "Epoch 95/200\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 0.8229 - accuracy: 0.6706 - val_loss: 303.1446 - val_accuracy: 0.4448\n",
      "Epoch 96/200\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 0.8379 - accuracy: 0.6697 - val_loss: 437.9567 - val_accuracy: 0.4090\n",
      "Epoch 97/200\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 0.8318 - accuracy: 0.6819 - val_loss: 537.8395 - val_accuracy: 0.3927\n",
      "Epoch 98/200\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.8241 - accuracy: 0.6772 - val_loss: 322.8424 - val_accuracy: 0.3468\n",
      "Epoch 99/200\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.8118 - accuracy: 0.6728 - val_loss: 200.5696 - val_accuracy: 0.5139\n",
      "Epoch 100/200\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.8408 - accuracy: 0.6678 - val_loss: 212.9915 - val_accuracy: 0.4550\n",
      "Epoch 101/200\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 0.8279 - accuracy: 0.6719 - val_loss: 220.3152 - val_accuracy: 0.3906\n",
      "Epoch 102/200\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.8059 - accuracy: 0.6763 - val_loss: 549.9028 - val_accuracy: 0.4111\n",
      "Epoch 103/200\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 0.8193 - accuracy: 0.6850 - val_loss: 345.9970 - val_accuracy: 0.4360\n",
      "Epoch 104/200\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.7953 - accuracy: 0.6957 - val_loss: 211.3443 - val_accuracy: 0.3400\n",
      "Epoch 105/200\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 0.7785 - accuracy: 0.6944 - val_loss: 217.4917 - val_accuracy: 0.3983\n",
      "Epoch 106/200\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 0.8072 - accuracy: 0.6797 - val_loss: 738.5458 - val_accuracy: 0.3593\n",
      "Epoch 107/200\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 0.7987 - accuracy: 0.6828 - val_loss: 858.0723 - val_accuracy: 0.4355\n",
      "Epoch 108/200\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.7517 - accuracy: 0.7113 - val_loss: 173.3206 - val_accuracy: 0.4341\n",
      "Epoch 109/200\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.8024 - accuracy: 0.6888 - val_loss: 320.1364 - val_accuracy: 0.4407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 0.7960 - accuracy: 0.6888 - val_loss: 220.1249 - val_accuracy: 0.3541\n",
      "Epoch 111/200\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.8018 - accuracy: 0.6838 - val_loss: 205.2305 - val_accuracy: 0.4319\n",
      "Epoch 112/200\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.7714 - accuracy: 0.6944 - val_loss: 110.3435 - val_accuracy: 0.4289\n",
      "Epoch 113/200\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.7587 - accuracy: 0.6925 - val_loss: 376.2106 - val_accuracy: 0.3571\n",
      "Epoch 114/200\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.7665 - accuracy: 0.7054 - val_loss: 421.1124 - val_accuracy: 0.3546\n",
      "Epoch 115/200\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 0.7617 - accuracy: 0.7041 - val_loss: 136.8997 - val_accuracy: 0.4272\n",
      "Epoch 116/200\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.7900 - accuracy: 0.6900 - val_loss: 992.3782 - val_accuracy: 0.4446\n",
      "Epoch 117/200\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.7708 - accuracy: 0.7035 - val_loss: 326.4131 - val_accuracy: 0.4561\n",
      "Epoch 118/200\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.7721 - accuracy: 0.7029 - val_loss: 541.5400 - val_accuracy: 0.4357\n",
      "Epoch 119/200\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.7298 - accuracy: 0.7147 - val_loss: 461.5859 - val_accuracy: 0.4334\n",
      "Epoch 120/200\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.7728 - accuracy: 0.6982 - val_loss: 148.9853 - val_accuracy: 0.4874\n",
      "Epoch 121/200\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 0.7444 - accuracy: 0.7044 - val_loss: 498.2717 - val_accuracy: 0.4613\n",
      "Epoch 122/200\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 0.7482 - accuracy: 0.7079 - val_loss: 701.5942 - val_accuracy: 0.4409\n",
      "Epoch 123/200\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.7047 - accuracy: 0.7307 - val_loss: 302.2790 - val_accuracy: 0.4092\n",
      "Epoch 124/200\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 0.7498 - accuracy: 0.7032 - val_loss: 556.9601 - val_accuracy: 0.3944\n",
      "Epoch 125/200\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.7261 - accuracy: 0.7072 - val_loss: 991.6144 - val_accuracy: 0.4582\n",
      "Epoch 126/200\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.7077 - accuracy: 0.7311 - val_loss: 334.3258 - val_accuracy: 0.3551\n",
      "Epoch 127/200\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 0.7227 - accuracy: 0.7191 - val_loss: 396.2439 - val_accuracy: 0.4061\n",
      "Epoch 128/200\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.7129 - accuracy: 0.7207 - val_loss: 405.5502 - val_accuracy: 0.4409\n",
      "Epoch 129/200\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 0.7199 - accuracy: 0.7091 - val_loss: 433.8929 - val_accuracy: 0.4618\n",
      "Epoch 130/200\n",
      "100/100 [==============================] - 33s 328ms/step - loss: 0.6987 - accuracy: 0.7292 - val_loss: 683.7746 - val_accuracy: 0.4357\n",
      "Epoch 131/200\n",
      "100/100 [==============================] - 35s 352ms/step - loss: 0.7505 - accuracy: 0.7032 - val_loss: 415.1870 - val_accuracy: 0.4696\n",
      "Epoch 132/200\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 0.7015 - accuracy: 0.7173 - val_loss: 182.9257 - val_accuracy: 0.4953\n",
      "Epoch 133/200\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.6858 - accuracy: 0.7276 - val_loss: 375.9806 - val_accuracy: 0.4303\n",
      "Epoch 134/200\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 0.7330 - accuracy: 0.7094 - val_loss: 550.8303 - val_accuracy: 0.4608\n",
      "Epoch 135/200\n",
      "100/100 [==============================] - 27s 275ms/step - loss: 0.6935 - accuracy: 0.7232 - val_loss: 940.7144 - val_accuracy: 0.4861\n",
      "Epoch 136/200\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.6982 - accuracy: 0.7285 - val_loss: 176.7132 - val_accuracy: 0.4210\n",
      "Epoch 137/200\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 0.7124 - accuracy: 0.7194 - val_loss: 775.2457 - val_accuracy: 0.3442\n",
      "Epoch 138/200\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.7014 - accuracy: 0.7242 - val_loss: 621.3643 - val_accuracy: 0.3964\n",
      "Epoch 139/200\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.6737 - accuracy: 0.7367 - val_loss: 453.0432 - val_accuracy: 0.4061\n",
      "Epoch 140/200\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.6586 - accuracy: 0.7376 - val_loss: 679.6188 - val_accuracy: 0.4393\n",
      "Epoch 141/200\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 0.6864 - accuracy: 0.7316 - val_loss: 355.7454 - val_accuracy: 0.5067\n",
      "Epoch 142/200\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.6725 - accuracy: 0.7354 - val_loss: 105.6597 - val_accuracy: 0.3787\n",
      "Epoch 143/200\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 0.6716 - accuracy: 0.7414 - val_loss: 495.7123 - val_accuracy: 0.3963\n",
      "Epoch 144/200\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 0.6875 - accuracy: 0.7322 - val_loss: 366.6087 - val_accuracy: 0.3562\n",
      "Epoch 145/200\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 0.6842 - accuracy: 0.7348 - val_loss: 405.1160 - val_accuracy: 0.4082\n",
      "Epoch 146/200\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.6617 - accuracy: 0.7437 - val_loss: 202.9957 - val_accuracy: 0.3452\n",
      "Epoch 147/200\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.6494 - accuracy: 0.7505 - val_loss: 530.6135 - val_accuracy: 0.3808\n",
      "Epoch 148/200\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.6487 - accuracy: 0.7473 - val_loss: 296.5586 - val_accuracy: 0.3996\n",
      "Epoch 149/200\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.6896 - accuracy: 0.7270 - val_loss: 311.5723 - val_accuracy: 0.4407\n",
      "Epoch 150/200\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 0.6423 - accuracy: 0.7504 - val_loss: 126.5231 - val_accuracy: 0.4435\n",
      "Epoch 151/200\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.6538 - accuracy: 0.7401 - val_loss: 740.3680 - val_accuracy: 0.4020\n",
      "Epoch 152/200\n",
      "100/100 [==============================] - 27s 275ms/step - loss: 0.6522 - accuracy: 0.7502 - val_loss: 385.1473 - val_accuracy: 0.3326\n",
      "Epoch 153/200\n",
      "100/100 [==============================] - 35s 347ms/step - loss: 0.6327 - accuracy: 0.7516 - val_loss: 646.2035 - val_accuracy: 0.4087\n",
      "Epoch 154/200\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.6433 - accuracy: 0.7436 - val_loss: 590.7903 - val_accuracy: 0.4561\n",
      "Epoch 155/200\n",
      "100/100 [==============================] - 34s 343ms/step - loss: 0.6536 - accuracy: 0.7461 - val_loss: 543.7941 - val_accuracy: 0.4180\n",
      "Epoch 156/200\n",
      "100/100 [==============================] - 35s 349ms/step - loss: 0.6223 - accuracy: 0.7610 - val_loss: 275.2543 - val_accuracy: 0.4555\n",
      "Epoch 157/200\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 0.6306 - accuracy: 0.7552 - val_loss: 559.7799 - val_accuracy: 0.4644\n",
      "Epoch 158/200\n",
      "100/100 [==============================] - 36s 363ms/step - loss: 0.6250 - accuracy: 0.7516 - val_loss: 404.9862 - val_accuracy: 0.4639\n",
      "Epoch 159/200\n",
      "100/100 [==============================] - 34s 336ms/step - loss: 0.6343 - accuracy: 0.7473 - val_loss: 539.9468 - val_accuracy: 0.3927\n",
      "Epoch 160/200\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.6472 - accuracy: 0.7505 - val_loss: 4.9670e-06 - val_accuracy: 0.3949\n",
      "Epoch 161/200\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 0.6490 - accuracy: 0.7492 - val_loss: 540.9020 - val_accuracy: 0.4164\n",
      "Epoch 162/200\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.6252 - accuracy: 0.7576 - val_loss: 266.9412 - val_accuracy: 0.4106\n",
      "Epoch 163/200\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 0.6194 - accuracy: 0.7510 - val_loss: 426.4521 - val_accuracy: 0.4401\n",
      "Epoch 164/200\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.6390 - accuracy: 0.7480 - val_loss: 521.4571 - val_accuracy: 0.4064\n",
      "Epoch 165/200\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.6332 - accuracy: 0.7548 - val_loss: 315.7714 - val_accuracy: 0.4267\n",
      "Epoch 166/200\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.5939 - accuracy: 0.7642 - val_loss: 220.2311 - val_accuracy: 0.4252\n",
      "Epoch 167/200\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.6203 - accuracy: 0.7595 - val_loss: 507.8168 - val_accuracy: 0.4138\n",
      "Epoch 168/200\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.6213 - accuracy: 0.7548 - val_loss: 324.0246 - val_accuracy: 0.4304\n",
      "Epoch 169/200\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.6205 - accuracy: 0.7583 - val_loss: 756.4570 - val_accuracy: 0.4076\n",
      "Epoch 170/200\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 0.5963 - accuracy: 0.7664 - val_loss: 289.7718 - val_accuracy: 0.4393\n",
      "Epoch 171/200\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.6305 - accuracy: 0.7595 - val_loss: 363.4547 - val_accuracy: 0.4143\n",
      "Epoch 172/200\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 0.5948 - accuracy: 0.7708 - val_loss: 862.3594 - val_accuracy: 0.4273\n",
      "Epoch 173/200\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 0.6274 - accuracy: 0.7523 - val_loss: 520.2638 - val_accuracy: 0.4407\n",
      "Epoch 174/200\n",
      "100/100 [==============================] - 36s 363ms/step - loss: 0.5887 - accuracy: 0.7726 - val_loss: 237.8954 - val_accuracy: 0.3740\n",
      "Epoch 175/200\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 0.6062 - accuracy: 0.7627 - val_loss: 450.7148 - val_accuracy: 0.3937\n",
      "Epoch 176/200\n",
      "100/100 [==============================] - 36s 361ms/step - loss: 0.6102 - accuracy: 0.7654 - val_loss: 180.5246 - val_accuracy: 0.4221\n",
      "Epoch 177/200\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 0.5848 - accuracy: 0.7705 - val_loss: 718.9534 - val_accuracy: 0.3777\n",
      "Epoch 178/200\n",
      "100/100 [==============================] - 35s 352ms/step - loss: 0.6289 - accuracy: 0.7516 - val_loss: 0.0000e+00 - val_accuracy: 0.4022\n",
      "Epoch 179/200\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.5930 - accuracy: 0.7626 - val_loss: 1240.7200 - val_accuracy: 0.4432\n",
      "Epoch 180/200\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 0.6312 - accuracy: 0.7617 - val_loss: 191.4403 - val_accuracy: 0.4351\n",
      "Epoch 181/200\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.5847 - accuracy: 0.7682 - val_loss: 562.3381 - val_accuracy: 0.4623\n",
      "Epoch 182/200\n",
      "100/100 [==============================] - 39s 387ms/step - loss: 0.6043 - accuracy: 0.7652 - val_loss: 644.5999 - val_accuracy: 0.4090\n",
      "Epoch 183/200\n",
      "100/100 [==============================] - 36s 361ms/step - loss: 0.5771 - accuracy: 0.7817 - val_loss: 507.9799 - val_accuracy: 0.4154\n",
      "Epoch 184/200\n",
      "100/100 [==============================] - 36s 359ms/step - loss: 0.6006 - accuracy: 0.7627 - val_loss: 172.3251 - val_accuracy: 0.4189\n",
      "Epoch 185/200\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 0.5535 - accuracy: 0.7918 - val_loss: 638.8380 - val_accuracy: 0.3911\n",
      "Epoch 186/200\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 0.5743 - accuracy: 0.7716 - val_loss: 589.2891 - val_accuracy: 0.4111\n",
      "Epoch 187/200\n",
      "100/100 [==============================] - 36s 361ms/step - loss: 0.5538 - accuracy: 0.7824 - val_loss: 292.8647 - val_accuracy: 0.3829\n",
      "Epoch 188/200\n",
      "100/100 [==============================] - 35s 349ms/step - loss: 0.5722 - accuracy: 0.7799 - val_loss: 189.8035 - val_accuracy: 0.4529\n",
      "Epoch 189/200\n",
      "100/100 [==============================] - 35s 352ms/step - loss: 0.5744 - accuracy: 0.7767 - val_loss: 435.9932 - val_accuracy: 0.4608\n",
      "Epoch 190/200\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 0.5351 - accuracy: 0.7967 - val_loss: 832.3301 - val_accuracy: 0.4116\n",
      "Epoch 191/200\n",
      "100/100 [==============================] - 35s 351ms/step - loss: 0.5470 - accuracy: 0.7905 - val_loss: 712.6908 - val_accuracy: 0.3870\n",
      "Epoch 192/200\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 0.5713 - accuracy: 0.7754 - val_loss: 790.7318 - val_accuracy: 0.4372\n",
      "Epoch 193/200\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 0.5699 - accuracy: 0.7760 - val_loss: 503.8632 - val_accuracy: 0.4180\n",
      "Epoch 194/200\n",
      "100/100 [==============================] - 37s 365ms/step - loss: 0.5577 - accuracy: 0.7849 - val_loss: 128.7383 - val_accuracy: 0.4425\n",
      "Epoch 195/200\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 0.5842 - accuracy: 0.7680 - val_loss: 486.7669 - val_accuracy: 0.3720\n",
      "Epoch 196/200\n",
      "100/100 [==============================] - 36s 361ms/step - loss: 0.5392 - accuracy: 0.7917 - val_loss: 596.4697 - val_accuracy: 0.4430\n",
      "Epoch 197/200\n",
      " 53/100 [==============>...............] - ETA: 13s - loss: 0.5847 - accuracy: 0.7738"
     ]
    }
   ],
   "source": [
    "model.fit_generator(x_train, steps_per_epoch =100, epochs = 200, validation_data = x_test, validation_steps = 63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Skin_Diseases.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
